# InsightAudio

**InsightAudio** — полностью локальный сервис для автоматической расшифровки аудио/видео и генерации структурированных пересказов с помощью современных ИИ‑моделей. Все данные обрабатываются и хранятся только на вашем устройстве, гарантируя приватность и безопасность.

---

## Возможности

- Загружайте аудио или видео и автоматически получайте качественную транскрипцию текста.
- Генерируйте структурированный пересказ (summary) с отдельными разделами — удобно для протоколов встреч, лекций, звонков, обучающих материалов.
- Выбирайте и скачивайте различные ИИ‑модели (Whisper, Vosk, Llama, Gemma и др.) для обработки — как для расшифровки речи, так и для summary.
- Все модели и конфигурационные файлы хранятся вне Docker-контейнера: легко менять, обновлять, расширять стек.
- Docker-контейнер включает удобный веб-интерфейс (порт 55667) для отслеживания статуса, выбора модели и скачивания результатов.
- Гибкая настройка шаблонов пересказа, конфигурации обработки, поддержка txt, md, docx.
- Максимум приватности: ваши данные под полным контролем, только локально.

---

## Быстрый старт

1. Клонируйте репозиторий InsightAudio и перейдите в его папку.
2. Создайте каталоги `models/` и `config/` (в корне), дайте права на запись.
3. Соберите контейнер:

    ```
    docker-compose build
    ```

4. Запустите web-сервис:

    ```
    docker-compose up
    ```

5. Откройте [http://localhost:55667](http://localhost:55667) — загружайте аудио/видео, выбирайте модели, скачивайте результаты.

---

## Структура проекта

InsightAudio/
├── app/
│ ├── main.py
│ ├── transcriber.py
│ ├── summarizer.py
│ ├── models.py
│ ├── file_utils.py
│ ├── config_manager.py
│ └── templates/
│ ├── index.html
│ └── results.html
├── Dockerfile
├── requirements.txt
├── docker-compose.yml
├── models/
├── config/
└── README.md




Вот пошаговые команды для запуска InsightAudio и начала работы:

***

1. **Клонируйте или подготовьте директорию InsightAudio:**

```bash
git clone <URL_вашего_репозитория> insightaudio
cd insightaudio
```

2. **Создайте каталоги для моделей и конфигураций (если их нет):**

```bash
mkdir -p models config tmp
```

3. **Соберите Docker-образ (если первый запуск):**

```bash
docker-compose build
```
или
```bash
docker build -t insightaudio .
```

4. **Запустите контейнер с volume и портами (через docker-compose):**

```bash
docker-compose up
```

5. **Проверьте, что сервис стартовал — откройте в браузере:**
```
http://localhost:55667
```

***

**Дополнительно:**

- Для обновления контейнера после изменения кода:
  ```bash
  docker-compose build
  docker-compose up
  ```

- Для удаления остановленного контейнера:
  ```bash
  docker-compose down
  ```

- Каталоги `models/` и `config/` останутся на вашем диске даже при обновлении/удалении контейнера.

***

**После запуска:**
- Используйте веб-интерфейс: загружайте свой аудио/видео файл, выбирайте и скачивайте необходимые модели, запускайте обработку и скачивайте результаты.

***

Если потребуется добавить Ollama-сервер локально для работы с LLM-саммаризацией, запустите (на хосте):

```bash
ollama serve
```
и скачайте нужные модели:
```bash
ollama pull llama3:8b
```

***

Все готово к работе! Если нужна тестовая демонстрация или любой файл — запросите отдельно.